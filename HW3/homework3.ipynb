{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "This assignment will briefly cover two major types of deep learning models:\n",
    "discriminative and generative. You will first implement a simple convolutional\n",
    "neural network (CNN) to classify handwritten digit images from the MNIST\n",
    "dataset. Then, you will implement a varitional autoencoder (VAE) to generate\n",
    "images of handwritten digits that mimic the ones in MNIST.\n",
    "\n",
    "**Models need to be implemented in PyTorch**. If you are new to PyTorch, the\n",
    "[official tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "is a great place to get started.\n",
    "\n",
    "You need a CUDA-compatible GPU to train the models. If your own computer is\n",
    "not equipped with one, you can finish this assignment using Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Classification with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Load and Visualize Data (5 points)\n",
    "\n",
    "Let's first load the MNIST dataset with the help of TorchVision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='data', train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, pick 10 samples from the dataset, and visualize the\n",
    "images and the corresponding labels using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 10, figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    # TODO\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the original training set into a training set and a validation set.\n",
    "The model will be trained on the training set, and the validation set will be\n",
    "used to tune any hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original training set into a training set and a validation set.\n",
    "generator = torch.Generator().manual_seed(1231)\n",
    "num_train_samples = int(0.8 * len(dataset))\n",
    "num_val_samples = len(dataset) - num_train_samples\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset,\n",
    "    [num_train_samples, num_val_samples], generator=generator)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# Feel free to change these parameters.\n",
    "train_kwargs = {\n",
    "    'batch_size': 64,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 1,\n",
    "    'pin_memory': True,\n",
    "}\n",
    "test_kwargs = {\n",
    "    'batch_size': 64,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 1,\n",
    "    'pin_memory': True,\n",
    "}\n",
    "\n",
    "# Create data loaders.\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, **train_kwargs)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Implement CNN (20 points)\n",
    "\n",
    "In the following cell, implement a neural network that can classify MNIST images\n",
    "into 10 classes corresponding to digits 0-9. The network should satifies the\n",
    "following requirements:\n",
    "- It must contain convolutional layers.\n",
    "- It takes single-channel images of size 28 x 28 as input, and outputs\n",
    "  a 10-dimensional score vector for each sample in the batch.\n",
    "- The output scores should be unnormalized logits (i.e., not the output of a\n",
    "  softmax layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\"\"\"\n",
    "        # TODO\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Train the Model (20 points)\n",
    "\n",
    "Complete the training loop in the following cell and train your model.\n",
    "\n",
    "Notice the model outputs unnormalized logits, so be sure to choose the\n",
    "approapriate loss function (`criterion` in the code). You are allowed to use\n",
    "existing loss functions provided by PyTorch (either the Module version in\n",
    "`torch.nn` or the function version in `torch.nn.functional`).\n",
    "\n",
    "You are encouraged to experiment with different optimizers and hyperparameters,\n",
    "and use any optimizer of your choice in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    criterion: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    log_interval: int,\n",
    ") -> None:\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader, start=1):\n",
    "        loss =  # TODO\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Epoch {:>2d} [{:>6,}/{:>6,}] loss={:.3f}\".format(\n",
    "                epoch,\n",
    "                batch_idx * len(data),\n",
    "                len(data_loader.dataset),\n",
    "                loss.item(),\n",
    "            ))\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            # TODO\n",
    "\n",
    "    print(\"Test accuracy: {:>6,}/{:>6,} ({:.2f}%)\".format(\n",
    "        num_correct,\n",
    "        len(data_loader.dataset),\n",
    "        100. * num_correct / len(data_loader.dataset),\n",
    "    ))\n",
    "\n",
    "# TODO\n",
    "num_epochs =\n",
    "learning_rate =\n",
    "# Other hyperparameters:\n",
    "\n",
    "cnn =\n",
    "criterion =\n",
    "optimizer =\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(cnn, train_loader, criterion, optimizer, device, epoch, log_interval=150)\n",
    "    test(cnn, val_loader, device)\n",
    "\n",
    "torch.save(cnn.state_dict(), 'output/mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Evaluate the Model on the Test Set (5 points)\n",
    "\n",
    "In the following cell, load the test split of the MNIST dataset and evaluate\n",
    "your trained model on it. Report the accuracy of your model.\n",
    "\n",
    "The test set is supposed to be held out until you have finished model training.\n",
    "If you have hyperparameters to tune, please do so on the validation set instead\n",
    "of the test set.\n",
    "\n",
    "To receive full credit, your model should achieve an accuracy of at least 97.00%\n",
    "on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset =  # TODO\n",
    "test_loader =  # TODO\n",
    "test(cnn, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Generation with VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will implement a variational autoencoder (VAE) that can\n",
    "generate images of handwriten digits as if they were drawn from the actual MNIST\n",
    "dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Evaluation Metric: Inception Score (5 points)\n",
    "\n",
    "Before building the model, we first introduce how the generated samples will be\n",
    "quantitatively evaluated. Specifically, we use the *Inception Score* introduced\n",
    "in [[link](https://arxiv.org/abs/1606.03498)]. The name comes from applying an\n",
    "Inception network (pretrained on ImageNet) on generated images, and making use\n",
    "of statistics of the predicted class probabilities. In this assignment, you're\n",
    "not going to actually use the Inception network. Instead, you will use the CNN\n",
    "model you implemented in Q1 as the scoring model.\n",
    "\n",
    "The idea behind the Inception Score is simple. Ideally, we want the generated\n",
    "samples to be (1) realistic and (2) diverse. For one specific generated image to\n",
    "be realistic (i.e., actually look like a handwritten digit), the CNN model\n",
    "should predict a high score for one and only one of the 10 classes. For the set\n",
    "of generated images to be diverse, the probabilities should spread out across\n",
    "the 10 classes when averaged over all generated images. Quantitatively, these\n",
    "translate to (1) the probability distribution for each sample having low\n",
    "entropy, and (2) the average probability distribution over all samples having\n",
    "high entropy.\n",
    "\n",
    "To aid your implementation, the following cell already implements the scoring\n",
    "function for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "def compute_inception_score(\n",
    "    scoring_model: nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    num_splits: int = 10,\n",
    ") -> Tuple[float, float]:\n",
    "\n",
    "    scoring_model.eval()\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "\n",
    "            # HACK: Samples can be (image, label) pairs like those from the\n",
    "            # TorchVision datasets, or simply images from data loaders directly\n",
    "            # created on generated image samples.\n",
    "            if isinstance(data, (list, tuple)):\n",
    "                data = data[0]\n",
    "\n",
    "            data = data.to(device)\n",
    "            logits = scoring_model(data)\n",
    "            batch_probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "            probs.append(batch_probs)\n",
    "    probs = torch.cat(probs, dim=0).cpu().numpy()\n",
    "\n",
    "    split_scores = []\n",
    "    for i in range(num_splits):\n",
    "        n = len(probs) // num_splits\n",
    "        split_probs = probs[i*n:(i+1)*n]\n",
    "        # Ideally, high entropy with the averaged probabilities (diverse\n",
    "        # samples), and low average entropy with probabilities of individual\n",
    "        # samples (high quality samples).\n",
    "        log_scores = entropy(np.mean(split_probs, axis=0)) \\\n",
    "            - np.mean(entropy(split_probs, axis=1))\n",
    "        split_scores.append(np.exp(log_scores))\n",
    "    split_scores = np.array(split_scores)\n",
    "\n",
    "    mean = split_scores.mean()\n",
    "    std = split_scores.std()\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, evaluate the Inception Score on real MNIST images. You\n",
    "should use the CNN model you implemented and trained in Q1 as the scoring model,\n",
    "and use all images in the *test* split of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std =  # TODO\n",
    "print(\"Inception score: {:.2f}±{:.2f}\".format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Implement VAE (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, implement a variational autoencoder (VAE) that can\n",
    "generate images of handwritten digits. The VAE should satisfy the following\n",
    "requirements:\n",
    "\n",
    "- Its encoder should contain convolutional layers.\n",
    "- Its decoder should contain transposed convolutional layers.\n",
    "- The output of the decoder should be unnormalized logits for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"A simple variational autoencoder.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - latent_dim: The dimension of the latent space.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        # TODO\n",
    "        self.encoder =\n",
    "        self.fc_mu =\n",
    "        self.fc_logvar =\n",
    "        self.decoder =\n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        - x: (N, C, W, H), a batch of input images.\n",
    "\n",
    "        Returns:\n",
    "        - mu: (N, D), the mean of the latent distribution.\n",
    "        - logvar: (N, D), the log-variance of the latent distribution.\n",
    "        \"\"\"\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(\n",
    "        self,\n",
    "        mu: torch.Tensor,\n",
    "        logvar: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        - mu: (N, D), the mean of the latent distribution.\n",
    "        - logvar: (N, D), the log-variance of the latent distribution.\n",
    "\n",
    "        Returns:\n",
    "        - z: (N, D), a sample from the latent distribution.\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(\n",
    "        self,\n",
    "        z: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        - z: (N, D), a sample from the latent distribution.\n",
    "\n",
    "        Returns:\n",
    "        - recon: (N, C, W, H), unnormalized logits of the reconstructed images.\n",
    "        \"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Train the Model (20 points)\n",
    "\n",
    "Complete the training loop in the following cell and train your VAE. The loss\n",
    "function has already been implemented for you. If you are interested in how this\n",
    "loss function is derived, the following tutorial is a good reference:\n",
    "[[link](https://arxiv.org/abs/1606.05908)].\n",
    "\n",
    "After each epoch, you should generate some sample images using the current\n",
    "decoder and visualize them in the output cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(\n",
    "    image: torch.Tensor,\n",
    "    recon: torch.Tensor,\n",
    "    mu: torch.Tensor,\n",
    "    logvar: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    loss_recon = nn.functional.binary_cross_entropy_with_logits(\n",
    "        recon, image, reduction='sum')\n",
    "    loss_kldiv = 0.5 * torch.sum(mu**2 + logvar.exp() - 1 - logvar)\n",
    "\n",
    "    loss_recon /= image.size(0)\n",
    "    loss_kldiv /= image.size(0)\n",
    "    loss = loss_recon + loss_kldiv\n",
    "\n",
    "    return loss, loss_recon.detach(), loss_kldiv.detach()\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    criterion: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    log_interval: int,\n",
    ") -> None:\n",
    "    model.train()\n",
    "    for batch_idx, (data, _) in enumerate(data_loader, start=1):\n",
    "        # TODO\n",
    "        loss, loss_recon, loss_kldiv =\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Epoch {:>2d} [{:>6,}/{:>6,}] \".format(\n",
    "                epoch,\n",
    "                batch_idx * len(data),\n",
    "                len(data_loader.dataset),\n",
    "            ) + ' '.join(\n",
    "                f\"{name}={value:.3f}\" for name, value in [\n",
    "                    ('loss', loss.item()),\n",
    "                    ('loss_recon', loss_recon.item()),\n",
    "                    ('loss_kldiv', loss_kldiv.item()),\n",
    "            ]))\n",
    "\n",
    "\n",
    "def sample_and_visualize(\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    num_rows: int = 4,\n",
    "    num_cols: int = 8,\n",
    ") -> None:\n",
    "    num_samples = num_rows * num_cols\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # TODO\n",
    "        samples =\n",
    "        # Normalize the pixels to [0, 1] since the model outputs logits.\n",
    "        samples = samples.sigmoid()\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols, num_rows))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(samples[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# TODO\n",
    "# Feel free to add other hyperparameters.\n",
    "num_epochs: int =\n",
    "learning_rate: float =\n",
    "\n",
    "vae =\n",
    "criterion = vae_loss\n",
    "optimizer =\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(vae, train_loader, criterion, optimizer, device, epoch, 150)\n",
    "    sample_and_visualize(vae, device)\n",
    "\n",
    "torch.save(vae.state_dict(), 'output/mnist_vae.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Generate Images and Evaluate (5 points)\n",
    "\n",
    "In the following cell, generate 10,000 sample images using your trained VAE.\n",
    "Calculate and report the Inception Score on the generated images.\n",
    "\n",
    "To receive full credit, your VAE should achieve a mean Inception Score of at\n",
    "least 3.00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    # TODO\n",
    "    samples =\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(samples, batch_size=64)\n",
    "mean, std = compute_inception_score(cnn, data_loader, device)\n",
    "print(\"Inception score: {:.2f}±{:.2f}\".format(mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2022fall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
